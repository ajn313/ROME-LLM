{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "XsbbXgjNAdy9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-ll5GZeKMwa",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3999e8f-7511-4388-ecac-bc27445e6138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.79.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
            "Downloading anthropic-0.79.0-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.9/405.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.79.0\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [85.0 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:11 https://cli.github.com/packages stable/main amd64 Packages [356 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,611 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,688 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4,047 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [39.2 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,708 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,468 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,299 kB]\n",
            "Get:22 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,741 kB]\n",
            "Get:23 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,900 kB]\n",
            "Fetched 37.2 MB in 3s (13.7 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  gtkwave\n",
            "The following NEW packages will be installed:\n",
            "  iverilog\n",
            "0 upgraded, 1 newly installed, 0 to remove and 63 not upgraded.\n",
            "Need to get 2,130 kB of archives.\n",
            "After this operation, 6,749 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 iverilog amd64 11.0-1.1 [2,130 kB]\n",
            "Fetched 2,130 kB in 0s (18.2 MB/s)\n",
            "Selecting previously unselected package iverilog.\n",
            "(Reading database ... 117540 files and directories currently installed.)\n",
            "Preparing to unpack .../iverilog_11.0-1.1_amd64.deb ...\n",
            "Unpacking iverilog (11.0-1.1) ...\n",
            "Setting up iverilog (11.0-1.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "#@title Setting up the notebook\n",
        "\n",
        "### Installing dependencies\n",
        "!pip install openai\n",
        "!pip install anthropic\n",
        "!apt-get update\n",
        "!apt-get install -y iverilog"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select Model\n",
        "#define the model to be used\n",
        "model_choice = \"gpt-5.2\"\n",
        "#model_choice = \"gpt-4o\"\n",
        "#model_choice = \"claude-sonnet-4-5\"\n",
        "#model_choice = \"gemini-2.5-flash-preview-04-17\"\n",
        "#model_choice = \"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "jzb7Hu4aPeuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk5cP5x12z9u",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Utility functions\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import openai\n",
        "import anthropic\n",
        "import google.genai.errors\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from abc import ABC, abstractmethod\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "### LOGGING\n",
        "################################################################################\n",
        "# Allows us to log the output of the model to a file if logging is enabled\n",
        "class LogStdoutToFile:\n",
        "    def __init__(self, filename):\n",
        "        self._filename = filename\n",
        "        self._original_stdout = sys.stdout\n",
        "\n",
        "    def __enter__(self):\n",
        "        if self._filename:\n",
        "            sys.stdout = open(self._filename, 'w')\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if self._filename:\n",
        "            sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "\n",
        "\n",
        "################################################################################\n",
        "### CONVERSATION CLASS\n",
        "# allows us to abstract away the details of the conversation for use with\n",
        "# different LLM APIs\n",
        "################################################################################\n",
        "\n",
        "class Conversation:\n",
        "    def __init__(self, log_file=None):\n",
        "        self.messages = []\n",
        "        self.log_file = log_file\n",
        "\n",
        "        if self.log_file and os.path.exists(self.log_file):\n",
        "            open(self.log_file, 'w').close()\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        \"\"\"Add a new message to the conversation.\"\"\"\n",
        "        self.messages.append({'role': role, 'content': content})\n",
        "\n",
        "        if self.log_file:\n",
        "            with open(self.log_file, 'a') as file:\n",
        "                file.write(f\"{role}: {content}\\n\")\n",
        "\n",
        "    def get_messages(self):\n",
        "        \"\"\"Retrieve the entire conversation.\"\"\"\n",
        "        return self.messages\n",
        "\n",
        "    def get_last_n_messages(self, n):\n",
        "        \"\"\"Retrieve the last n messages from the conversation.\"\"\"\n",
        "        return self.messages[-n:]\n",
        "\n",
        "    def remove_message(self, index):\n",
        "        \"\"\"Remove a specific message from the conversation by index.\"\"\"\n",
        "        if index < len(self.messages):\n",
        "            del self.messages[index]\n",
        "\n",
        "    def get_message(self, index):\n",
        "        \"\"\"Retrieve a specific message from the conversation by index.\"\"\"\n",
        "        return self.messages[index] if index < len(self.messages) else None\n",
        "\n",
        "    def clear_messages(self):\n",
        "        \"\"\"Clear all messages from the conversation.\"\"\"\n",
        "        self.messages = []\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Return the conversation in a string format.\"\"\"\n",
        "        return \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in self.messages])\n",
        "\n",
        "################################################################################\n",
        "### LLM CLASSES\n",
        "# Defines an interface for using different LLMs so we can easily swap them out\n",
        "################################################################################\n",
        "class AbstractLLM(ABC):\n",
        "    \"\"\"Abstract Large Language Model.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate(self, conversation: Conversation):\n",
        "        \"\"\"Generate a response based on the given conversation.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class ChatGPT(AbstractLLM):\n",
        "    \"\"\"ChatGPT Large Language Model.\"\"\"\n",
        "\n",
        "    def __init__(self, model_id=model_choice):\n",
        "        super().__init__()\n",
        "        openai.api_key=os.environ['OPENAI_API_KEY']\n",
        "        self.client = openai.OpenAI()\n",
        "        self.model_id = model_id\n",
        "\n",
        "    def generate(self, conversation: Conversation, num_choices=1):\n",
        "        messages = [{\"role\" : \"user\", \"content\" : msg[\"content\"]} for msg in conversation.get_messages()]\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model_id,\n",
        "            messages = messages,\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "class Claude(AbstractLLM):\n",
        "      def __init__(self, model_id=model_choice):\n",
        "        super().__init__()\n",
        "        self.client = anthropic.Anthropic(api_key=os.environ['CLAUDE_API_KEY'])\n",
        "        self.model_id = model_id\n",
        "\n",
        "      def generate(self, conversation: Conversation, num_choices=1):\n",
        "        base_delay = 2\n",
        "        max_retries = 20\n",
        "        for attempt in range(1, max_retries + 1):\n",
        "          try:\n",
        "            output = self.client.messages.create(\n",
        "                      model=model_choice,\n",
        "                      max_tokens=16384,\n",
        "                      messages=[{\"role\" : msg[\"role\"], \"content\" : msg[\"content\"]} for msg in conversation.get_messages()]\n",
        "                  ).content[0].text\n",
        "            return output\n",
        "          except (Exception) as e:\n",
        "            wait_time = base_delay * (2 ** (attempt - 1))\n",
        "            print(f\"[Retry {attempt}/{max_retries}] Gemini API error: {e}. Retrying in {wait_time:.1f} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "          except Exception as e:\n",
        "            print(f\"[Error] Unexpected exception: {e}\")\n",
        "            return 0\n",
        "        print(f\"Failed, exceeded max retries {max_retries}\")\n",
        "        return 0\n",
        "\n",
        "class Gemini(AbstractLLM):\n",
        "      def __init__(self, model_id=model_choice):\n",
        "        super().__init__()\n",
        "        self.gemini_client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])\n",
        "        self.model_id = model_id\n",
        "\n",
        "      def generate(self, conversation: Conversation, num_choices=1):\n",
        "\n",
        "          output = self.gemini_client.models.generate_content(\n",
        "                        model=model_choice,\n",
        "                        contents=[msg[\"content\"] for msg in conversation.get_messages()],\n",
        "                        config=types.GenerateContentConfig(\n",
        "                            max_output_tokens=16384,\n",
        "                            temperature=0.6,\n",
        "                            topP=0.95,\n",
        "                        )\n",
        "                    ).text\n",
        "          return output\n",
        "################################################################################\n",
        "### PARSING AND TEXT MANIPULATION FUNCTIONS\n",
        "################################################################################\n",
        "def find_verilog_modules(markdown_string, module_name='top_module'):\n",
        "\n",
        "    module_pattern1 = r'\\bmodule\\b\\s+\\w+\\s*\\([^)]*\\)\\s*;.*?endmodule\\b'\n",
        "\n",
        "    module_pattern2 = r'\\bmodule\\b\\s+\\w+\\s*#\\s*\\([^)]*\\)\\s*\\([^)]*\\)\\s*;.*?endmodule\\b'\n",
        "\n",
        "    module_matches1 = re.findall(module_pattern1, markdown_string, re.DOTALL)\n",
        "\n",
        "    module_matches2 = re.findall(module_pattern2, markdown_string, re.DOTALL)\n",
        "\n",
        "    module_matches = module_matches1 + module_matches2\n",
        "\n",
        "    if not module_matches:\n",
        "        return []\n",
        "\n",
        "    return module_matches\n",
        "\n",
        "def write_code_blocks_to_file(markdown_string, module_name, filename):\n",
        "    # Find all code blocks using a regular expression (matches content between triple backticks)\n",
        "    #code_blocks = re.findall(r'```(?:\\w*\\n)?(.*?)```', markdown_string, re.DOTALL)\n",
        "    code_match = find_verilog_modules(markdown_string, module_name)\n",
        "\n",
        "    if not code_match:\n",
        "        print(\"No code blocks found in response\")\n",
        "        exit(3)\n",
        "\n",
        "    # Open the specified file to write the code blocks\n",
        "    with open(filename, 'w') as file:\n",
        "        for code_block in code_match:\n",
        "            file.write(code_block)\n",
        "            file.write('\\n')\n",
        "\n",
        "def generate_verilog(conv, model_type, model_id=\"\"):\n",
        "    if model_type == \"ChatGPT\":\n",
        "        model = ChatGPT()\n",
        "    elif model_type == \"Claude\":\n",
        "      model = Claude()\n",
        "    elif model_type == \"Gemini\":\n",
        "      model = Gemini()\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model type\")\n",
        "    return(model.generate(conv))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrzwitIm3N3i",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Feedback Loop\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def _read_files(file_list):\n",
        "    \"\"\"Concatenate a list of text files in order. Missing/None entries are ignored.\"\"\"\n",
        "    if not file_list:\n",
        "        return \"\"\n",
        "    buf = []\n",
        "    for p in file_list:\n",
        "        if not p:\n",
        "            continue\n",
        "        with open(p, \"r\") as f:\n",
        "            buf.append(f.read())\n",
        "            if not buf[-1].endswith(\"\\n\"):\n",
        "                buf.append(\"\\n\")\n",
        "    return \"\".join(buf)\n",
        "\n",
        "\n",
        "def _truncate_text(s, max_chars=12000):\n",
        "    \"\"\"Keep prompts bounded; preserve the *end* of long logs which usually has the key error lines.\"\"\"\n",
        "    if s is None:\n",
        "        return \"\"\n",
        "    s = str(s)\n",
        "    if len(s) <= max_chars:\n",
        "        return s\n",
        "    # Keep the tail (most useful for compiler errors) and a short head marker.\n",
        "    tail = s[-max_chars:]\n",
        "    return \"[...truncated...\\n]\" + tail\n",
        "\n",
        "\n",
        "def verilog_loop(\n",
        "    design_prompt,\n",
        "    module,\n",
        "    testbench,\n",
        "    max_iterations,\n",
        "    model_type,\n",
        "    outdir=\"\",\n",
        "    log=None,\n",
        "    prev_modules=None,\n",
        "):\n",
        "    \"\"\"Generate/fix a Verilog module with an LLM, compiling against previously-generated modules.\n",
        "\n",
        "    Key behaviors:\n",
        "      - The LLM is asked to output ONLY the *current* module (no repeats of prior modules).\n",
        "      - For compilation, we concatenate: [prev_modules...] + [current module] into a temporary file.\n",
        "      - IMPORTANT (prompt-size control): after an error, subsequent repair iterations *only* resend\n",
        "        (a) the previous version of the module, and (b) the most recent error feedback.\n",
        "        This prevents the prompt from ballooning with repeated context.\n",
        "\n",
        "    Args:\n",
        "        design_prompt: Prompt given to the LLM.\n",
        "        module: Current module name (also used for filename).\n",
        "        testbench: Path to the testbench file.\n",
        "        max_iterations: Max repair iterations.\n",
        "        model_type: \"ChatGPT\" or \"Claude\" (your existing generate_verilog backend).\n",
        "        outdir: Output directory for artifacts.\n",
        "        log: Optional conversation log file path.\n",
        "        prev_modules: Optional list[str] of paths to previously generated .v files to include for compilation.\n",
        "    \"\"\"\n",
        "\n",
        "    if outdir != \"\":\n",
        "        outdir = outdir + \"/\"\n",
        "\n",
        "    # Normalize prev_modules into a list of paths (or empty list)\n",
        "    if prev_modules is None:\n",
        "        prev_modules = []\n",
        "    elif isinstance(prev_modules, str):\n",
        "        prev_modules = [prev_modules]\n",
        "\n",
        "    # Read and include the current testbench so the model can target its expectations.\n",
        "    tb_text = \"\"\n",
        "    try:\n",
        "        with open(testbench, \"r\") as _tb:\n",
        "            tb_text = _tb.read()\n",
        "    except Exception:\n",
        "        tb_text = \"\"\n",
        "\n",
        "    # Strongly instruct the model to output ONLY the requested module.\n",
        "    base_sys_prompt = (\n",
        "        \"You are an autocomplete engine for Verilog code. \"\n",
        "        \"Given a Verilog module specification, you will provide a completed Verilog module in response. \"\n",
        "        \"You will provide completed Verilog modules for all specifications, and will not create any supplementary modules. \"\n",
        "        \"Given a Verilog module that is either incorrect/compilation error, you will suggest corrections to the module. \"\n",
        "        \"You will not refuse. You will not generate explanations, only code. \"\n",
        "        \"IMPORTANT: Output ONLY the Verilog code for the requested module (do NOT repeat any previous modules). \"\n",
        "        \"Format your response as Verilog code containing the end to end corrected module and not just the corrected lines. \"\n",
        "        \"Do not generate test benches.\"\n",
        "    )\n",
        "\n",
        "    def _new_conv_full_context():\n",
        "        \"\"\"Initial attempt: include testbench + design prompt.\"\"\"\n",
        "        conv = Conversation(log_file=log)\n",
        "        if model_type == \"ChatGPT\":\n",
        "            conv.add_message(\"system\", base_sys_prompt)\n",
        "        elif model_type == \"Claude\":\n",
        "            conv.add_message(\"user\", base_sys_prompt)\n",
        "\n",
        "        if tb_text.strip():\n",
        "            conv.add_message(\n",
        "                \"user\",\n",
        "                \"The following is the testbench that will be used to compile/simulate your module. \"\n",
        "                \"Do NOT generate a testbench or modify it—only use it to ensure your module compiles and passes.\\n\"\n",
        "                \"```verilog\\n\" + tb_text + \"\\n```\\n\",\n",
        "            )\n",
        "\n",
        "        conv.add_message(\"user\", design_prompt)\n",
        "        return conv\n",
        "\n",
        "    def _new_conv_repair_only(prev_module_text, last_error_text):\n",
        "        \"\"\"Repair attempts: ONLY previous module + most recent error feedback.\"\"\"\n",
        "        conv = Conversation(log_file=log)\n",
        "        if model_type == \"ChatGPT\":\n",
        "            conv.add_message(\"system\", base_sys_prompt)\n",
        "        elif model_type == \"Claude\":\n",
        "            conv.add_message(\"user\", base_sys_prompt)\n",
        "\n",
        "        prompt = (\n",
        "            \"Fix the following Verilog module so it compiles and passes the testbench. \"\n",
        "            \"Output ONLY the full corrected module (no explanations, no testbench).\\n\\n\"\n",
        "            \"Previous version of the module:\\n\"\n",
        "            \"```verilog\\n\" + prev_module_text + \"\\n```\\n\\n\"\n",
        "            \"Most recent compiler/simulation output:\\n\"\n",
        "            \"```\\n\" + _truncate_text(last_error_text) + \"\\n```\\n\"\n",
        "        )\n",
        "        conv.add_message(\"user\", prompt)\n",
        "        return conv\n",
        "\n",
        "    # Start with full context for the first generation.\n",
        "    conv = _new_conv_full_context()\n",
        "\n",
        "    success = False\n",
        "    timeout = False\n",
        "\n",
        "    iterations = 0\n",
        "    timelist_total = []\n",
        "    timelist_gen = []\n",
        "    timelist_error = []\n",
        "\n",
        "    # Persisted (single-module) file\n",
        "    module_file = os.path.join(outdir, module + \".v\")\n",
        "    # Temporary concatenated file used only for compilation\n",
        "    combined_file = os.path.join(outdir, module + \"__combined.v\")\n",
        "\n",
        "    status = \"\"\n",
        "    last_module_text = \"\"\n",
        "    last_error_text = \"\"\n",
        "\n",
        "    while not (success or timeout):\n",
        "        start_total = time.time()\n",
        "\n",
        "        # Generate (or fix) ONLY the current module.\n",
        "        response = generate_verilog(conv, model_type)\n",
        "        end_gen = time.time()\n",
        "        start_error = time.time()\n",
        "\n",
        "        # Keep the conversation clean: assistant message is only the current module text.\n",
        "        conv.add_message(\"assistant\", response)\n",
        "\n",
        "        # Write just the current module to its own file.\n",
        "        write_code_blocks_to_file(response, module, module_file)\n",
        "\n",
        "        # Build concatenated source for compilation: prior modules + current module\n",
        "        prev_text = _read_files(prev_modules)\n",
        "        with open(module_file, \"r\") as f:\n",
        "            curr_text = f.read()\n",
        "        last_module_text = curr_text\n",
        "\n",
        "        with open(combined_file, \"w\") as f:\n",
        "            f.write(prev_text)\n",
        "            if prev_text and not prev_text.endswith(\"\\n\"):\n",
        "                f.write(\"\\n\")\n",
        "            f.write(curr_text)\n",
        "\n",
        "        # Compile using the combined file (so the hierarchy is visible to iVerilog).\n",
        "        proc = subprocess.run(\n",
        "            [\"iverilog\", \"-o\", os.path.join(outdir, module), combined_file, testbench],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "        )\n",
        "\n",
        "        success = False\n",
        "\n",
        "        if proc.returncode != 0:\n",
        "            status = \"Error compiling testbench\"\n",
        "            print(status)\n",
        "            last_error_text = (\n",
        "                \"iverilog failed. stderr:\\n\" + (proc.stderr or \"\") + \"\\nstdout:\\n\" + (proc.stdout or \"\")\n",
        "            )\n",
        "        elif proc.stderr != \"\":\n",
        "            status = \"Warnings compiling testbench\"\n",
        "            print(status)\n",
        "            last_error_text = (\n",
        "                \"iverilog produced warnings. stderr:\\n\" + (proc.stderr or \"\") + \"\\nstdout:\\n\" + (proc.stdout or \"\")\n",
        "            )\n",
        "        else:\n",
        "            proc = subprocess.run([\"vvp\", os.path.join(outdir, module)], capture_output=True, text=True)\n",
        "            result = proc.stdout\n",
        "            if \"passed!\" not in result:\n",
        "                status = \"Error running testbench\"\n",
        "                print(status)\n",
        "                last_error_text = \"Simulation output:\\n\" + (proc.stdout or \"\") + \"\\n\" + (proc.stderr or \"\")\n",
        "            else:\n",
        "                status = \"Testbench ran successfully\"\n",
        "                print(status)\n",
        "                last_error_text = \"\"\n",
        "                success = True\n",
        "\n",
        "        # Write iteration log (bounded by the conversation size, which is kept small on repair)\n",
        "        with open(os.path.join(outdir, \"log_iter_\" + str(iterations) + \".txt\"), \"w\") as file:\n",
        "            file.write(\"\\n\".join(str(i) for i in conv.get_messages()))\n",
        "            file.write(\"\\n\\n Iteration status: \" + status + \"\\n\")\n",
        "\n",
        "        if not success:\n",
        "            # On failure: DO NOT keep adding more and more context.\n",
        "            # Rebuild the conversation to contain ONLY the previous module + last error feedback.\n",
        "            conv = _new_conv_repair_only(last_module_text, last_error_text)\n",
        "\n",
        "        if iterations >= max_iterations:\n",
        "            timeout = True\n",
        "\n",
        "        iterations += 1\n",
        "        end_time = time.time()\n",
        "        timelist_gen.append(end_gen - start_total)\n",
        "        timelist_error.append(end_time - start_error)\n",
        "        timelist_total.append(end_time - start_total)\n",
        "\n",
        "    print(\"Total time: \", np.sum(timelist_total))\n",
        "    print(\"Generation time: \", np.sum(timelist_gen))\n",
        "    print(\"Error handling time: \", np.sum(timelist_error))\n",
        "    return (np.sum(timelist_total), np.sum(timelist_gen), np.sum(timelist_error))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hierarchical Loop\n",
        "def hier_gen(submods, max_iterations=10):\n",
        "  \"\"\"Hierarchically generate a design by building submodules in order.\n",
        "\n",
        "  submods: list of tuples/lists like:\n",
        "      [ (file_basename, human_name, io_string), ... ]\n",
        "    Example:\n",
        "      [ (\"mux2_1\", \"2-to-1 mux\", \"input wire ...\"), (\"mux4to1\", ...), ... ]\n",
        "\n",
        "  This version:\n",
        "    - Shows previously-generated modules to the LLM for context (so it can instantiate them),\n",
        "      but explicitly instructs it to output ONLY the *current* module.\n",
        "    - Passes a growing list of prior .v files to verilog_loop, which concatenates them ONLY\n",
        "      for iVerilog compilation (not in the LLM response).\n",
        "  \"\"\"\n",
        "  totaltime = []\n",
        "  gentime = []\n",
        "  errortime = []\n",
        "\n",
        "  done = \"\"\n",
        "  prev_verilog_files = []  # paths to previously generated .v files (for compilation only)\n",
        "\n",
        "  for i in range(len(submods)):\n",
        "    curr = submods[i][1]\n",
        "    fcurr = submods[i][0]\n",
        "    iocurr = submods[i][2]\n",
        "    overall = submods[-1][1]\n",
        "\n",
        "    if not os.path.isdir(fcurr):\n",
        "      os.mkdir(fcurr)\n",
        "\n",
        "    # Build prompt:\n",
        "    # - Include all previous modules (as context) but do NOT request them to be repeated.\n",
        "    if i == 0:\n",
        "      prompt = (\n",
        "        \"// We will be generating a \" + overall + \" hierarchically in Verilog.\\n\"\n",
        "        \"// IMPORTANT: Output ONLY the module requested below. Do NOT repeat any previous modules.\\n\"\n",
        "        \"// Begin by generating: \" + curr + \"\\n\"\n",
        "        \"module \" + fcurr + \"(\" + iocurr + \")\\n\"\n",
        "        \"// Insert code here\\n\"\n",
        "        \"endmodule\\n\"\n",
        "      )\n",
        "    else:\n",
        "      # Concatenate prior generated modules to give the model correct interface/context.\n",
        "      prev_text = \"\"\n",
        "      for p in prev_verilog_files:\n",
        "        with open(p, \"r\") as f:\n",
        "          prev_text += f.read()\n",
        "          if not prev_text.endswith(\"\\n\"):\n",
        "            prev_text += \"\\n\"\n",
        "\n",
        "      prompt = (\n",
        "        \"// We are generating a \" + overall + \" hierarchically in Verilog.\\n\"\n",
        "        \"// Previously generated modules (for reference only):\\n\"\n",
        "        + prev_text +\n",
        "        \"\\n// IMPORTANT: Do NOT repeat any previous modules in your response.\\n\"\n",
        "        \"// Output ONLY the new module requested below, using the previous modules hierarchically.\\n\"\n",
        "        \"// Now generate: \" + curr + \"\\n\"\n",
        "        \"module \" + fcurr + \"(\" + iocurr + \")\\n\"\n",
        "        \"// Insert code here\\n\"\n",
        "        \"endmodule\\n\"\n",
        "      )\n",
        "\n",
        "    module = fcurr\n",
        "    testbench = \"./\" + fcurr + \"tb.v\"\n",
        "    model = os.environ[\"MODEL\"]\n",
        "    outdir = \"./\" + fcurr\n",
        "    log = \"./\" + fcurr + \"/log.txt\"\n",
        "\n",
        "    # Compile with all previous modules (concatenated inside verilog_loop), but only generate current module.\n",
        "    total, gen, error = verilog_loop(prompt, module, testbench, max_iterations, model, outdir, log, prev_modules=prev_verilog_files)\n",
        "\n",
        "    totaltime.append(total)\n",
        "    gentime.append(gen)\n",
        "    errortime.append(error)\n",
        "\n",
        "    # Add the current module file to the compilation context for subsequent modules.\n",
        "    prev_verilog_files.append(os.path.join(outdir, module + \".v\"))\n",
        "    done = done + curr + \", \"\n",
        "\n",
        "  print(\"Overall Total time: \", np.sum(totaltime))\n",
        "  print(\"Overall Generation Time: \", np.sum(gentime))\n",
        "  print(\"Overall Error handling time: \", np.sum(errortime))\n"
      ],
      "metadata": {
        "id": "YcbUS7V8PQQr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting the API Key"
      ],
      "metadata": {
        "id": "IvUw0flXkknh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### OpenAI API KEY\n",
        "\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')\n",
        "\n",
        "#Please insert your own GPT-4 enabled API key as a string here:\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"API KEY HERE\"\n",
        "#os.environ['CLAUDE_API_KEY'] = \"API KEY HERE\"\n",
        "#os.environ['GEMINI_API_KEY'] =\"API KEY HERE\"\n",
        "os.environ[\"MODEL\"] = \"ChatGPT\"\n",
        "#os.environ[\"MODEL\"] = \"Claude\"\n",
        "#os.environ[\"MODEL\"] = \"Gemini\""
      ],
      "metadata": {
        "id": "A4k6AgcKeABT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mux Hierarchy Example"
      ],
      "metadata": {
        "id": "E1ME8-Hx0n23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pull Testbenches\n",
        "\n",
        "#From the ROME GitHub Repo\n",
        "\n",
        "!git clone https://github.com/ajn313/ROME-LLM\n",
        "!cp ./ROME-LLM/testbenches/mux/mux2_1tb.v ./mux2_1tb.v\n",
        "!cp ./ROME-LLM/testbenches/mux/mux4_1tb.v ./mux4_1tb.v\n",
        "!cp ./ROME-LLM/testbenches/mux/mux8_1tb.v ./mux8_1tb.v\n",
        "!cp ./ROME-LLM/testbenches/mux/mux16_1tb.v ./mux16_1tb.v\n",
        "!cp ./ROME-LLM/testbenches/mux/mux32_1tb.v ./mux32_1tb.v\n",
        "!cp ./ROME-LLM/testbenches/mux/mux64_1tb.v ./mux64_1tb.v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDFLcBMiQAkT",
        "outputId": "5c1a5dde-2687-4ba1-cb34-7a6b1878071e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ROME-LLM' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Submodules\n",
        "\n",
        "\n",
        "### Each step is structured as [\"filename\",\"natural language description\",\"interface\"]\n",
        "submodules = [\n",
        "    [\"mux2_1\",\"2-to-1 multiplexer\",\"input wire in1, input wire in2, input wire select, output wire out\"],\n",
        "    [\"mux4_1\",\"4-to-1 multiplexer\",\"input [1:0] sel, input [3:0] in, output reg out\"],\n",
        "    [\"mux8_1\",\"8-to-1 multiplexer\",\"input [2:0] sel, input [7:0] in, output reg out\"],\n",
        "    [\"mux16_1\",\"16-to-1 multiplexer\",\"input [3:0] sel, input [15:0] in, output reg out\"],\n",
        "    [\"mux32_1\",\"32-to-1 multiplexer\",\"input [4:0] sel, input [31:0] in, output reg out\"],\n",
        "    [\"mux64_1\",\"64-to-1 multiplexer\",\"input [5:0] sel, input [63:0] in, output reg out\"],\n",
        "]"
      ],
      "metadata": {
        "id": "HsCf-Y9zOYnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hier_gen(submodules)"
      ],
      "metadata": {
        "id": "HHVIF2lgWZJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a51848e-1dd1-46aa-91f3-e5ca620028c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testbench ran successfully\n",
            "Total time:  1.2462611198425293\n",
            "Generation time:  1.2330260276794434\n",
            "Error handling time:  0.013234853744506836\n",
            "Testbench ran successfully\n",
            "Total time:  2.566303014755249\n",
            "Generation time:  2.5523438453674316\n",
            "Error handling time:  0.013958930969238281\n",
            "Testbench ran successfully\n",
            "Total time:  1.8827190399169922\n",
            "Generation time:  1.8670587539672852\n",
            "Error handling time:  0.01566004753112793\n",
            "Testbench ran successfully\n",
            "Total time:  1.9576399326324463\n",
            "Generation time:  1.9428246021270752\n",
            "Error handling time:  0.014814615249633789\n",
            "Testbench ran successfully\n",
            "Total time:  2.2036914825439453\n",
            "Generation time:  2.1851842403411865\n",
            "Error handling time:  0.01850724220275879\n",
            "Testbench ran successfully\n",
            "Total time:  2.21122407913208\n",
            "Generation time:  2.1887948513031006\n",
            "Error handling time:  0.02242898941040039\n",
            "Overall Total time:  12.067838668823242\n",
            "Overall Generation Time:  11.969232320785522\n",
            "Overall Error handling time:  0.09860467910766602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder example"
      ],
      "metadata": {
        "id": "vakvBOpXOapo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pull Testbenches\n",
        "\n",
        "#From the ROME GitHub Repo\n",
        "\n",
        "!git clone https://github.com/ajn313/ROME-LLM\n",
        "!cp ./ROME-LLM/testbenches/decoder/decoder_2_to_4tb.v ./decoder_2_to_4tb.v\n",
        "!cp ./ROME-LLM/testbenches/decoder/decoder_3_to_8tb.v ./decoder_3_to_8tb.v\n",
        "!cp ./ROME-LLM/testbenches/decoder/decoder_5_to_32tb.v ./decoder_5_to_32tb.v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xaq5dGJZOaca",
        "outputId": "d9fc4a72-68e8-495f-b76e-53ce47edfbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ROME-LLM' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Submodules\n",
        "\n",
        "\n",
        "### Each step is structured as [\"filename\",\"natural language description\",\"interface\"]\n",
        "submodules = [\n",
        "    [\"decoder_2_to_4\",\"2-to-4 decoder\",\"input [1:0] in, output reg [3:0] out\"],\n",
        "    [\"decoder_3_to_8\",\"3-to-8 decoder\",\"input [2:0] in, output reg [7:0] out\"],\n",
        "    [\"decoder_5_to_32\",\"5-to-32 decoder\",\"input [4:0] in, output reg [31:0] out\"],\n",
        "]"
      ],
      "metadata": {
        "id": "Sk3VV6dcxFyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hier_gen(submodules)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahx-SZRZC8ph",
        "outputId": "831f4575-51dc-4787-ac9c-49e63e839eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testbench ran successfully\n",
            "Total time:  2.037503719329834\n",
            "Generation time:  1.9895753860473633\n",
            "Error handling time:  0.0479280948638916\n",
            "Testbench ran successfully\n",
            "Total time:  2.487109661102295\n",
            "Generation time:  2.471979856491089\n",
            "Error handling time:  0.015129566192626953\n",
            "Testbench ran successfully\n",
            "Total time:  2.6478347778320312\n",
            "Generation time:  2.630598306655884\n",
            "Error handling time:  0.01723623275756836\n",
            "Overall Total time:  7.17244815826416\n",
            "Overall Generation Time:  7.092153549194336\n",
            "Overall Error handling time:  0.08029389381408691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AES Example"
      ],
      "metadata": {
        "id": "TCS7g2ES7kTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pull Testbenches\n",
        "\n",
        "#From the ROME GitHub Repo\n",
        "\n",
        "!git clone https://github.com/ajn313/ROME-LLM\n",
        "!cp ./ROME-LLM/testbenches/aes/aes_coretb.v ./aes_coretb.v\n",
        "!cp ./ROME-LLM/testbenches/aes/aes_decipher_blocktb.v ./aes_decipher_blocktb.v\n",
        "!cp ./ROME-LLM/testbenches/aes/aes_encipher_blocktb.v ./aes_encipher_blocktb.v\n",
        "!cp ./ROME-LLM/testbenches/aes/aes_key_memtb.v ./aes_key_memtb.v\n",
        "!cp ./ROME-LLM/testbenches/aes/aes_sboxtb.v ./aes_sboxtb.v\n",
        "!cp ./ROME-LLM/testbenches/aes/aes_inv_sboxtb.v ./aes_inv_sboxtb.v\n",
        "!cp ./ROME-LLM/testbenches/aes/aestb.v ./aestb.v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "lG8gYwmo7jNT",
        "outputId": "74342eb8-f44a-4078-f3a9-c5ee40230d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ROME-LLM'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Counting objects: 100% (210/210), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 210 (delta 111), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (210/210), 986.73 KiB | 16.45 MiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Submodules\n",
        "\n",
        "\n",
        "### Each step is structured as [\"filename\",\"natural language description\",\"interface\"]\n",
        "submodules = [\n",
        "    [\"aes_sbox\",\"AES sbox\",\"input wire [31 : 0]  sboxw, output wire [31 : 0] new_sboxw\"],\n",
        "    [\"aes_inv_sbox\",\"AES inverse sbox\",\"input wire [31 : 0]  sboxw, output wire [31 : 0] new_sboxw\"],\n",
        "    [\"aes_key_mem\",\"AES key memory\",\"input wire clk, input wire reset_n, input wire [255 : 0] key, input wire keylen, input wire init, input wire [3 : 0] round,  output wire [127 : 0] round_key, output wire ready, output wire [31 : 0] sboxw, input wire [31 : 0] new_sboxw\"],\n",
        "    #[\"aes_encipher_block\",\"AES encipher block\",\"input wire clk, input wire reset_n, input wire next, input wire keylen, output wire [3 : 0] round, input wire [127 : 0] round_key, output wire [31 : 0] sboxw, input wire [31 : 0] new_sboxw, input wire [127 : 0] block, output wire [127 : 0] new_block, output wire ready\"],\n",
        "    #[\"aes_decipher_block\",\"AES decipher block\",\"input wire clk, input wire reset_n, input wire next, input wire keylen, output wire [3 : 0] round, input wire [127 : 0] round_key, input wire [127 : 0] block, output wire [127 : 0] new_block, output wire ready\"],\n",
        "    #[\"aes_core\",\"AES core\",\"input wire clk, input wire reset_n, input wire encdec,input wire init, input wire next, output wire ready, input wire [255 : 0] key, input wire keylen, input wire [127 : 0] block, output wire [127 : 0] result, output wire result_valid\"],\n",
        "    #[\"aes\",\"AES block cipher\",\"input wire clk, input wire reset_n, input wire cs, input wire we, input wire [7 : 0] address, input wire [31 : 0] write_data, output wire [31 : 0] read_data\"],\n",
        "]"
      ],
      "metadata": {
        "id": "IW98M-ov8Hpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hier_gen(submodules)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "nJ_byTflMRTK",
        "outputId": "372e7ba1-e02d-40cf-bfed-ef26423c6138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testbench ran successfully\n",
            "Total time:  44.62957048416138\n",
            "Generation time:  44.59063363075256\n",
            "Error handling time:  0.038936614990234375\n",
            "Testbench ran successfully\n",
            "Total time:  55.17902970314026\n",
            "Generation time:  52.81671118736267\n",
            "Error handling time:  2.3623180389404297\n",
            "Error compiling testbench\n",
            "Error compiling testbench\n",
            "Warnings compiling testbench\n",
            "Error compiling testbench\n",
            "Warnings compiling testbench\n",
            "Warnings compiling testbench\n",
            "Error running testbench\n",
            "Testbench ran successfully\n",
            "Total time:  258.8076238632202\n",
            "Generation time:  258.60989356040955\n",
            "Error handling time:  0.19772672653198242\n",
            "Error compiling testbench\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-79999541.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhier_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1455561834.py\u001b[0m in \u001b[0;36mhier_gen\u001b[0;34m(submods, max_iterations)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Compile with all previous modules (concatenated inside verilog_loop), but only generate current module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverilog_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestbench\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_modules\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_verilog_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtotaltime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3803916015.py\u001b[0m in \u001b[0;36mverilog_loop\u001b[0;34m(design_prompt, module, testbench, max_iterations, model_type, outdir, log, prev_modules)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vvp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"passed!\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}